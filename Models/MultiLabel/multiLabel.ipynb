{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-multilearn in /home/codespace/.python/current/lib/python3.12/site-packages (0.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting scipy==1.9.3\n",
      "  Using cached scipy-1.9.3.tar.gz (42.1 MB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[50 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[36m\u001b[1m+ meson setup /tmp/pip-install-v7k855ec/scipy_52510a51a50244eb8c2b99b1173ecfd3 /tmp/pip-install-v7k855ec/scipy_52510a51a50244eb8c2b99b1173ecfd3/.mesonpy-l6fgpupp -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/tmp/pip-install-v7k855ec/scipy_52510a51a50244eb8c2b99b1173ecfd3/.mesonpy-l6fgpupp/meson-python-native-file.ini\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The Meson build system\n",
      "  \u001b[31m   \u001b[0m Version: 1.6.1\n",
      "  \u001b[31m   \u001b[0m Source dir: /tmp/pip-install-v7k855ec/scipy_52510a51a50244eb8c2b99b1173ecfd3\n",
      "  \u001b[31m   \u001b[0m Build dir: /tmp/pip-install-v7k855ec/scipy_52510a51a50244eb8c2b99b1173ecfd3/.mesonpy-l6fgpupp\n",
      "  \u001b[31m   \u001b[0m Build type: native build\n",
      "  \u001b[31m   \u001b[0m Project name: SciPy\n",
      "  \u001b[31m   \u001b[0m Project version: 1.9.3\n",
      "  \u001b[31m   \u001b[0m C compiler for the host machine: cc (gcc 9.4.0 \"cc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\")\n",
      "  \u001b[31m   \u001b[0m C linker for the host machine: cc ld.bfd 2.34\n",
      "  \u001b[31m   \u001b[0m C++ compiler for the host machine: c++ (gcc 9.4.0 \"c++ (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0\")\n",
      "  \u001b[31m   \u001b[0m C++ linker for the host machine: c++ ld.bfd 2.34\n",
      "  \u001b[31m   \u001b[0m Host machine cpu family: x86_64\n",
      "  \u001b[31m   \u001b[0m Host machine cpu: x86_64\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-but-set-variable: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-but-set-variable: YES (cached)\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-function: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-conversion: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-misleading-indentation: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-incompatible-pointer-types: YES\n",
      "  \u001b[31m   \u001b[0m Library m found: YES\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ../meson.build:57:0: ERROR: Unknown compiler(s): [['gfortran'], ['flang-new'], ['flang'], ['nvfortran'], ['pgfortran'], ['ifort'], ['ifx'], ['g95']]\n",
      "  \u001b[31m   \u001b[0m The following exception(s) were encountered:\n",
      "  \u001b[31m   \u001b[0m Running `gfortran --help` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `gfortran --version` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `gfortran -V` gave \"[Errno 2] No such file or directory: 'gfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new --help` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new --version` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang-new -V` gave \"[Errno 2] No such file or directory: 'flang-new'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang --help` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang --version` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `flang -V` gave \"[Errno 2] No such file or directory: 'flang'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran --help` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran --version` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `nvfortran -V` gave \"[Errno 2] No such file or directory: 'nvfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran --help` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran --version` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `pgfortran -V` gave \"[Errno 2] No such file or directory: 'pgfortran'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort --help` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort --version` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifort -V` gave \"[Errno 2] No such file or directory: 'ifort'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx --help` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx --version` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `ifx -V` gave \"[Errno 2] No such file or directory: 'ifx'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 --help` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 --version` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m Running `g95 -V` gave \"[Errno 2] No such file or directory: 'g95'\"\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m A full log can be found at /tmp/pip-install-v7k855ec/scipy_52510a51a50244eb8c2b99b1173ecfd3/.mesonpy-l6fgpupp/meson-logs/meson-log.txt\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "%pip install scikit-multilearn\n",
    "!pip install --upgrade scipy numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.adapt import MLARAM\n",
    "\n",
    "from skmultilearn.problem_transform import BinaryRelevance, ClassifierChain, LabelPowerset\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(592, 77)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amazed-suprised</th>\n",
       "      <th>happy-pleased</th>\n",
       "      <th>relaxing-clam</th>\n",
       "      <th>quiet-still</th>\n",
       "      <th>sad-lonely</th>\n",
       "      <th>angry-aggresive</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_Centroid</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_Rolloff</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_Flux</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_0</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_1</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_2</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_3</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_4</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_5</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_6</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_7</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_8</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_9</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_10</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_11</th>\n",
       "      <th>Mean_Acc1298_Mean_Mem40_MFCC_12</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_Centroid</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_Rolloff</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_Flux</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_0</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_1</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_2</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_3</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_4</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_5</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_6</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_7</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_8</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_9</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_10</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_11</th>\n",
       "      <th>Mean_Acc1298_Std_Mem40_MFCC_12</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_Centroid</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_Rolloff</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_Flux</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_0</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_1</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_2</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_3</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_4</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_5</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_6</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_7</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_8</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_9</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_10</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_11</th>\n",
       "      <th>Std_Acc1298_Mean_Mem40_MFCC_12</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_Centroid</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_Rolloff</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_Flux</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_0</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_1</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_2</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_3</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_4</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_5</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_6</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_7</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_8</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_9</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_10</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_11</th>\n",
       "      <th>Std_Acc1298_Std_Mem40_MFCC_12</th>\n",
       "      <th>BH_LowPeakAmp</th>\n",
       "      <th>BH_LowPeakBPM</th>\n",
       "      <th>BH_HighPeakAmp</th>\n",
       "      <th>BH_HighPeakBPM</th>\n",
       "      <th>BHSUM1</th>\n",
       "      <th>BHSUM2</th>\n",
       "      <th>BHSUM3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.132498</td>\n",
       "      <td>0.077848</td>\n",
       "      <td>0.229227</td>\n",
       "      <td>0.602629</td>\n",
       "      <td>0.512861</td>\n",
       "      <td>0.467404</td>\n",
       "      <td>0.529733</td>\n",
       "      <td>0.573498</td>\n",
       "      <td>0.592831</td>\n",
       "      <td>0.520031</td>\n",
       "      <td>0.598853</td>\n",
       "      <td>0.537699</td>\n",
       "      <td>0.780658</td>\n",
       "      <td>0.462982</td>\n",
       "      <td>0.407108</td>\n",
       "      <td>0.684364</td>\n",
       "      <td>0.135824</td>\n",
       "      <td>0.245631</td>\n",
       "      <td>0.157515</td>\n",
       "      <td>0.301285</td>\n",
       "      <td>0.350107</td>\n",
       "      <td>0.459476</td>\n",
       "      <td>0.583274</td>\n",
       "      <td>0.430053</td>\n",
       "      <td>0.416198</td>\n",
       "      <td>0.581916</td>\n",
       "      <td>0.342758</td>\n",
       "      <td>0.309345</td>\n",
       "      <td>0.388929</td>\n",
       "      <td>0.323521</td>\n",
       "      <td>0.455207</td>\n",
       "      <td>0.261390</td>\n",
       "      <td>0.027559</td>\n",
       "      <td>0.149077</td>\n",
       "      <td>0.195433</td>\n",
       "      <td>0.571354</td>\n",
       "      <td>0.326404</td>\n",
       "      <td>0.246745</td>\n",
       "      <td>0.524645</td>\n",
       "      <td>0.354798</td>\n",
       "      <td>0.240244</td>\n",
       "      <td>0.239788</td>\n",
       "      <td>0.128689</td>\n",
       "      <td>0.173252</td>\n",
       "      <td>0.204863</td>\n",
       "      <td>0.131632</td>\n",
       "      <td>0.245653</td>\n",
       "      <td>0.144607</td>\n",
       "      <td>0.258203</td>\n",
       "      <td>0.470051</td>\n",
       "      <td>0.259909</td>\n",
       "      <td>0.613640</td>\n",
       "      <td>0.458314</td>\n",
       "      <td>0.434716</td>\n",
       "      <td>0.448941</td>\n",
       "      <td>0.370609</td>\n",
       "      <td>0.285647</td>\n",
       "      <td>0.663082</td>\n",
       "      <td>0.297080</td>\n",
       "      <td>0.273671</td>\n",
       "      <td>0.286411</td>\n",
       "      <td>0.197026</td>\n",
       "      <td>0.196244</td>\n",
       "      <td>0.164323</td>\n",
       "      <td>0.030017</td>\n",
       "      <td>0.253968</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>0.240602</td>\n",
       "      <td>0.136735</td>\n",
       "      <td>0.058442</td>\n",
       "      <td>0.107594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.384281</td>\n",
       "      <td>0.355249</td>\n",
       "      <td>0.167190</td>\n",
       "      <td>0.853089</td>\n",
       "      <td>0.260577</td>\n",
       "      <td>0.332757</td>\n",
       "      <td>0.153930</td>\n",
       "      <td>0.519381</td>\n",
       "      <td>0.268043</td>\n",
       "      <td>0.251955</td>\n",
       "      <td>0.459922</td>\n",
       "      <td>0.430814</td>\n",
       "      <td>0.654323</td>\n",
       "      <td>0.641021</td>\n",
       "      <td>0.356511</td>\n",
       "      <td>0.647367</td>\n",
       "      <td>0.367659</td>\n",
       "      <td>0.539078</td>\n",
       "      <td>0.100569</td>\n",
       "      <td>0.133502</td>\n",
       "      <td>0.337194</td>\n",
       "      <td>0.319752</td>\n",
       "      <td>0.349012</td>\n",
       "      <td>0.171182</td>\n",
       "      <td>0.191357</td>\n",
       "      <td>0.390569</td>\n",
       "      <td>0.289253</td>\n",
       "      <td>0.208641</td>\n",
       "      <td>0.341328</td>\n",
       "      <td>0.265669</td>\n",
       "      <td>0.273736</td>\n",
       "      <td>0.181791</td>\n",
       "      <td>0.028513</td>\n",
       "      <td>0.252827</td>\n",
       "      <td>0.258190</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>0.236247</td>\n",
       "      <td>0.069285</td>\n",
       "      <td>0.192754</td>\n",
       "      <td>0.154258</td>\n",
       "      <td>0.128671</td>\n",
       "      <td>0.116726</td>\n",
       "      <td>0.059704</td>\n",
       "      <td>0.073697</td>\n",
       "      <td>0.080341</td>\n",
       "      <td>0.062701</td>\n",
       "      <td>0.075672</td>\n",
       "      <td>0.041256</td>\n",
       "      <td>0.207782</td>\n",
       "      <td>0.300735</td>\n",
       "      <td>0.888274</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.294673</td>\n",
       "      <td>0.210429</td>\n",
       "      <td>0.132036</td>\n",
       "      <td>0.167474</td>\n",
       "      <td>0.205996</td>\n",
       "      <td>0.155514</td>\n",
       "      <td>0.086631</td>\n",
       "      <td>0.071462</td>\n",
       "      <td>0.067492</td>\n",
       "      <td>0.093526</td>\n",
       "      <td>0.085649</td>\n",
       "      <td>0.025101</td>\n",
       "      <td>0.182955</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.156764</td>\n",
       "      <td>0.270677</td>\n",
       "      <td>0.191377</td>\n",
       "      <td>0.153728</td>\n",
       "      <td>0.197951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.541782</td>\n",
       "      <td>0.356491</td>\n",
       "      <td>0.152246</td>\n",
       "      <td>0.791142</td>\n",
       "      <td>0.228276</td>\n",
       "      <td>0.471278</td>\n",
       "      <td>0.378166</td>\n",
       "      <td>0.559905</td>\n",
       "      <td>0.279949</td>\n",
       "      <td>0.555830</td>\n",
       "      <td>0.521424</td>\n",
       "      <td>0.477018</td>\n",
       "      <td>0.541562</td>\n",
       "      <td>0.383692</td>\n",
       "      <td>0.301562</td>\n",
       "      <td>0.209283</td>\n",
       "      <td>0.469560</td>\n",
       "      <td>0.435643</td>\n",
       "      <td>0.117424</td>\n",
       "      <td>0.233075</td>\n",
       "      <td>0.214409</td>\n",
       "      <td>0.270485</td>\n",
       "      <td>0.448359</td>\n",
       "      <td>0.446847</td>\n",
       "      <td>0.272785</td>\n",
       "      <td>0.626050</td>\n",
       "      <td>0.457692</td>\n",
       "      <td>0.257535</td>\n",
       "      <td>0.486894</td>\n",
       "      <td>0.433737</td>\n",
       "      <td>0.429170</td>\n",
       "      <td>0.250437</td>\n",
       "      <td>0.173474</td>\n",
       "      <td>0.240775</td>\n",
       "      <td>0.166080</td>\n",
       "      <td>0.134165</td>\n",
       "      <td>0.149816</td>\n",
       "      <td>0.312213</td>\n",
       "      <td>0.351309</td>\n",
       "      <td>0.550984</td>\n",
       "      <td>0.241480</td>\n",
       "      <td>0.351404</td>\n",
       "      <td>0.324881</td>\n",
       "      <td>0.102732</td>\n",
       "      <td>0.214608</td>\n",
       "      <td>0.182897</td>\n",
       "      <td>0.131488</td>\n",
       "      <td>0.092507</td>\n",
       "      <td>0.539964</td>\n",
       "      <td>0.291858</td>\n",
       "      <td>0.894329</td>\n",
       "      <td>0.316151</td>\n",
       "      <td>0.345686</td>\n",
       "      <td>0.218272</td>\n",
       "      <td>0.254165</td>\n",
       "      <td>0.392987</td>\n",
       "      <td>0.243410</td>\n",
       "      <td>0.529933</td>\n",
       "      <td>0.272590</td>\n",
       "      <td>0.153845</td>\n",
       "      <td>0.314687</td>\n",
       "      <td>0.198082</td>\n",
       "      <td>0.108067</td>\n",
       "      <td>0.140574</td>\n",
       "      <td>0.099303</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.593985</td>\n",
       "      <td>0.105114</td>\n",
       "      <td>0.025555</td>\n",
       "      <td>0.122965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.174288</td>\n",
       "      <td>0.243935</td>\n",
       "      <td>0.254326</td>\n",
       "      <td>0.438987</td>\n",
       "      <td>0.480346</td>\n",
       "      <td>0.472862</td>\n",
       "      <td>0.473128</td>\n",
       "      <td>0.777076</td>\n",
       "      <td>0.376471</td>\n",
       "      <td>0.650178</td>\n",
       "      <td>0.518224</td>\n",
       "      <td>0.374862</td>\n",
       "      <td>0.717025</td>\n",
       "      <td>0.548050</td>\n",
       "      <td>0.385528</td>\n",
       "      <td>0.545977</td>\n",
       "      <td>0.266415</td>\n",
       "      <td>0.581436</td>\n",
       "      <td>0.213768</td>\n",
       "      <td>0.371697</td>\n",
       "      <td>0.267091</td>\n",
       "      <td>0.518605</td>\n",
       "      <td>0.521327</td>\n",
       "      <td>0.375596</td>\n",
       "      <td>0.516414</td>\n",
       "      <td>0.768118</td>\n",
       "      <td>0.668286</td>\n",
       "      <td>0.482510</td>\n",
       "      <td>0.515023</td>\n",
       "      <td>0.425579</td>\n",
       "      <td>0.448576</td>\n",
       "      <td>0.305121</td>\n",
       "      <td>0.095215</td>\n",
       "      <td>0.406613</td>\n",
       "      <td>0.200305</td>\n",
       "      <td>0.234013</td>\n",
       "      <td>0.173066</td>\n",
       "      <td>0.391382</td>\n",
       "      <td>0.352153</td>\n",
       "      <td>0.333506</td>\n",
       "      <td>0.491522</td>\n",
       "      <td>0.243034</td>\n",
       "      <td>0.189499</td>\n",
       "      <td>0.161029</td>\n",
       "      <td>0.185126</td>\n",
       "      <td>0.252305</td>\n",
       "      <td>0.203846</td>\n",
       "      <td>0.112363</td>\n",
       "      <td>0.440058</td>\n",
       "      <td>0.608967</td>\n",
       "      <td>0.854473</td>\n",
       "      <td>0.478910</td>\n",
       "      <td>0.378549</td>\n",
       "      <td>0.407442</td>\n",
       "      <td>0.393774</td>\n",
       "      <td>0.284080</td>\n",
       "      <td>0.622807</td>\n",
       "      <td>0.461229</td>\n",
       "      <td>0.444935</td>\n",
       "      <td>0.355792</td>\n",
       "      <td>0.298915</td>\n",
       "      <td>0.235793</td>\n",
       "      <td>0.220195</td>\n",
       "      <td>0.235834</td>\n",
       "      <td>0.024988</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.117169</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>0.057288</td>\n",
       "      <td>0.134575</td>\n",
       "      <td>0.091509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.347436</td>\n",
       "      <td>0.155448</td>\n",
       "      <td>0.100047</td>\n",
       "      <td>0.126026</td>\n",
       "      <td>0.456950</td>\n",
       "      <td>0.539992</td>\n",
       "      <td>0.301537</td>\n",
       "      <td>0.598898</td>\n",
       "      <td>0.361990</td>\n",
       "      <td>0.484839</td>\n",
       "      <td>0.646532</td>\n",
       "      <td>0.520983</td>\n",
       "      <td>0.887006</td>\n",
       "      <td>0.550650</td>\n",
       "      <td>0.373552</td>\n",
       "      <td>0.373699</td>\n",
       "      <td>0.178554</td>\n",
       "      <td>0.150008</td>\n",
       "      <td>0.045284</td>\n",
       "      <td>0.227232</td>\n",
       "      <td>0.183270</td>\n",
       "      <td>0.309233</td>\n",
       "      <td>0.188338</td>\n",
       "      <td>0.302628</td>\n",
       "      <td>0.275626</td>\n",
       "      <td>0.399990</td>\n",
       "      <td>0.478468</td>\n",
       "      <td>0.478095</td>\n",
       "      <td>0.644428</td>\n",
       "      <td>0.705417</td>\n",
       "      <td>0.737404</td>\n",
       "      <td>0.418726</td>\n",
       "      <td>0.340997</td>\n",
       "      <td>0.548333</td>\n",
       "      <td>0.273571</td>\n",
       "      <td>0.535455</td>\n",
       "      <td>0.514268</td>\n",
       "      <td>0.438880</td>\n",
       "      <td>0.367572</td>\n",
       "      <td>0.526058</td>\n",
       "      <td>0.485215</td>\n",
       "      <td>0.456886</td>\n",
       "      <td>0.424624</td>\n",
       "      <td>0.335312</td>\n",
       "      <td>0.485055</td>\n",
       "      <td>0.385908</td>\n",
       "      <td>0.523032</td>\n",
       "      <td>0.340229</td>\n",
       "      <td>0.503828</td>\n",
       "      <td>0.422766</td>\n",
       "      <td>0.918634</td>\n",
       "      <td>0.686384</td>\n",
       "      <td>0.474845</td>\n",
       "      <td>0.366783</td>\n",
       "      <td>0.218394</td>\n",
       "      <td>0.370754</td>\n",
       "      <td>0.481513</td>\n",
       "      <td>0.542680</td>\n",
       "      <td>0.695774</td>\n",
       "      <td>0.783841</td>\n",
       "      <td>0.827826</td>\n",
       "      <td>0.715683</td>\n",
       "      <td>0.573359</td>\n",
       "      <td>0.412368</td>\n",
       "      <td>0.016398</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.081703</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>0.108737</td>\n",
       "      <td>0.172882</td>\n",
       "      <td>0.189934</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   amazed-suprised  happy-pleased  relaxing-clam  ...    BHSUM1    BHSUM2    BHSUM3\n",
       "0                0              1              1  ...  0.136735  0.058442  0.107594\n",
       "1                1              0              0  ...  0.191377  0.153728  0.197951\n",
       "2                0              1              0  ...  0.105114  0.025555  0.122965\n",
       "3                0              0              1  ...  0.057288  0.134575  0.091509\n",
       "4                0              0              0  ...  0.108737  0.172882  0.189934\n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "musica = pd.read_csv(\"Musica.csv\")\n",
    "print(musica.shape)\n",
    "musica.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 1],\n",
       "       ...,\n",
       "       [0, 0, 1, 1, 1, 0],\n",
       "       [0, 1, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0]], shape=(592, 6))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe = musica.iloc[:, 0:6].values\n",
    "previsores = musica.iloc[:, 7:78].values\n",
    "classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_treinamento, x_teste, y_treinamento, y_teste = train_test_split(previsores, classe, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Module 'scipy' has no attribute 'ones'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/__init__.py:137\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mglobals\u001b[39;49m()[name]\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'ones'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/Artificial-Inteligence-study-cases/Models/MultiLabel/multiLabel.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bbookish-sniffle-x4gv6gw7pjxfpj97/workspaces/Artificial-Inteligence-study-cases/Models/MultiLabel/multiLabel.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m ann \u001b[39m=\u001b[39m MLARAM()\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bbookish-sniffle-x4gv6gw7pjxfpj97/workspaces/Artificial-Inteligence-study-cases/Models/MultiLabel/multiLabel.ipynb#W6sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m ann\u001b[39m.\u001b[39;49mfit(x_treinamento, y_treinamento)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/skmultilearn/adapt/mlaram.py:170\u001b[0m, in \u001b[0;36mMLARAM.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    167\u001b[0m y_0 \u001b[39m=\u001b[39m _get_label_vector(y, \u001b[39m0\u001b[39m)\n\u001b[1;32m    169\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneurons) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 170\u001b[0m     neuron_vc \u001b[39m=\u001b[39m _concatenate_with_negation(X[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    171\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneurons\u001b[39m.\u001b[39mappend(Neuron(neuron_vc, y_0))\n\u001b[1;32m    172\u001b[0m     start_index \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.12/site-packages/skmultilearn/adapt/mlaram.py:40\u001b[0m, in \u001b[0;36m_concatenate_with_negation\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_concatenate_with_negation\u001b[39m(row):\n\u001b[0;32m---> 40\u001b[0m     ones \u001b[39m=\u001b[39m scipy\u001b[39m.\u001b[39;49mones(row\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     41\u001b[0m     \u001b[39mif\u001b[39;00m issparse(row):\n\u001b[1;32m     42\u001b[0m         \u001b[39mreturn\u001b[39;00m scipy\u001b[39m.\u001b[39msparse\u001b[39m.\u001b[39mhstack((row, ones \u001b[39m-\u001b[39m row))\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/scipy/__init__.py:139\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mglobals\u001b[39m()[name]\n\u001b[1;32m    138\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[0;32m--> 139\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\n\u001b[1;32m    140\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModule \u001b[39m\u001b[39m'\u001b[39m\u001b[39mscipy\u001b[39m\u001b[39m'\u001b[39m\u001b[39m has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    141\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: Module 'scipy' has no attribute 'ones'"
     ]
    }
   ],
   "source": [
    "ann = MLARAM()\n",
    "ann.fit(x_treinamento, y_treinamento)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
